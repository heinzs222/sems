# =============================================================================
# Twilio Voice Agent Configuration
# =============================================================================
# Copy this file to `.env` and fill in your actual values.
# NEVER commit `.env` to version control.
# =============================================================================

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------
# Public hostname for Twilio WebSocket connection (NO scheme, e.g., xxxxx.ngrok-free.app)
PUBLIC_HOST=your-ngrok-subdomain.ngrok-free.app

# Server port (default: 7860)
PORT=7860

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Voice Mode
# -----------------------------------------------------------------------------
# Select the overall voice stack:
# - auto: use OpenAI Realtime when OPENAI_API_KEY is set, else pipeline
# - pipeline: Deepgram STT -> LLM -> TTS
# - openai_realtime: OpenAI Realtime speech-to-speech (audio in/out)
VOICE_MODE=auto

# -----------------------------------------------------------------------------
# Twilio Credentials
# -----------------------------------------------------------------------------
# Found at https://console.twilio.com/
TWILIO_ACCOUNT_SID=ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
TWILIO_AUTH_TOKEN=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# -----------------------------------------------------------------------------
# Deepgram (Speech-to-Text)
# -----------------------------------------------------------------------------
# Get your API key at https://console.deepgram.com/
DEEPGRAM_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Deepgram language codes (optional)
# English examples: en-US, en
# French examples: fr, fr-FR
DEEPGRAM_LANGUAGE_EN=en-US
DEEPGRAM_LANGUAGE_FR=fr

# Deepgram Flux (v2) turn-taking tuning (Late-2025 best practice)
# These only apply when /v2/listen is supported by your Deepgram account.
DEEPGRAM_EAGER_EOT_THRESHOLD=0.45
DEEPGRAM_EOT_THRESHOLD=0.72
DEEPGRAM_EOT_TIMEOUT_MS=4500

# -----------------------------------------------------------------------------
# Cartesia (Text-to-Speech)
# -----------------------------------------------------------------------------
# Get your API key at https://play.cartesia.ai/
CARTESIA_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Cartesia voice ID (optional, defaults to a standard voice)
CARTESIA_VOICE_ID=a0e99841-438c-4a64-b679-ae501e7d6091

# Optional: a dedicated French voice ID (used after you ask the agent to switch to French)
CARTESIA_VOICE_ID_FR=dd951538-c475-4bde-a3f7-9fd7b3e4d8f5

# -----------------------------------------------------------------------------
# TTS Provider (Voice Output)
# -----------------------------------------------------------------------------
# Select which TTS backend to use:
# - cartesia (default, streaming, CPU-friendly)
# - openai (OpenAI speech synthesis; non-streaming in this repo)
# - csm (contextual TTS via a GPU microservice; falls back to Cartesia)
TTS_PROVIDER=cartesia

# OpenAI TTS (only used when TTS_PROVIDER=openai)
OPENAI_TTS_MODEL=gpt-4o-mini-tts
OPENAI_TTS_VOICE=alloy

# OpenAI Realtime (only used when VOICE_MODE=openai_realtime)
# Notes:
# - This is speech-to-speech (no Deepgram/Cartesia/Groq required).
# - Use g711_ulaw so Twilio audio can pass through without resampling.
OPENAI_REALTIME_MODEL=gpt-4o-realtime-preview
OPENAI_REALTIME_VOICE=alloy
OPENAI_REALTIME_TURN_SILENCE_MS=350
OPENAI_REALTIME_INSTRUCTIONS=
# Optional: get Whisper transcripts in logs for debugging/analytics.
OPENAI_REALTIME_TRANSCRIPTION_MODEL=whisper-1

# CSM microservice (only used when TTS_PROVIDER=csm)
# Run the GPU service from `csm_service/` and set this to its public URL.
CSM_ENDPOINT=http://localhost:8001
CSM_TIMEOUT_MS=2500
CSM_MAX_CONTEXT_SECONDS=24
CSM_VOICE_STYLE=default

# -----------------------------------------------------------------------------
# LLM Provider (Groq or OpenAI / ChatGPT)
# -----------------------------------------------------------------------------
# Choose which LLM to use:
# - groq (default, fast/cheap)
# - openai (ChatGPT, generally "smarter" but can cost more)
LLM_PROVIDER=groq

# If using OpenAI (ChatGPT):
# Get your API key at https://platform.openai.com/
# Recommended models (pick one you have access to):
# - gpt-4.1 (best quality)
# - gpt-4o (excellent, multimodal)
# - gpt-4o-mini (cheaper, still strong)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# If using Groq:
# Get your API key at https://console.groq.com/
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Model to use - MUST exist in Groq's model list
# Popular options: llama-3.3-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768
GROQ_MODEL=llama-3.3-70b-versatile

# -----------------------------------------------------------------------------
# Feature Flags
# -----------------------------------------------------------------------------
# Enable semantic routing for fast cached responses
ROUTER_ENABLED=true

# Menu-only mode (recommended for this project): the agent will ONLY discuss the menu
# and take a simulated order (no store/address/hours chat).
MENU_ONLY=false

# Add short acknowledgement prefixes (e.g., "Got it,") before replies.
# Recommended: false (avoid repetitive filler).
TONE_PREFIX_ENABLED=false

# Enable memory/context persistence (placeholder - not implemented)
MEMORY_ENABLED=false

# Enable Outlines for constrained JSON extraction (experimental)
OUTLINES_ENABLED=false

# -----------------------------------------------------------------------------
# Agent Configuration
# -----------------------------------------------------------------------------
# Default language at call start ("en" or "fr")
DEFAULT_LANGUAGE=en

# Agent name for persona
AGENT_NAME=Sesame

# Company name for context
COMPANY_NAME=Sesame AI

# Maximum conversation history turns to keep
MAX_HISTORY_TURNS=10

# Silence timeout in seconds before agent responds (legacy; not required for Deepgram Flux)
SILENCE_TIMEOUT_SECONDS=1.5

# Turn-taking (avoid cutting callers off)
# When Deepgram emits a "final" transcript, the agent holds briefly before acting on it.
# This gives callers a natural moment to think and continue.
TURN_END_GRACE_MS=650
TURN_END_FALLBACK_MS=950
TURN_END_SHORT_UTTERANCE_MS=1200
TURN_END_INCOMPLETE_MS=1500

# Silence check-ins (gentle "still there?" behavior)
# - First check-in after N seconds of silence (after the agent finishes speaking)
# - Then wait longer between any additional check-ins
# - Stops after max prompts until the caller speaks again
SILENCE_CHECKIN_FIRST_S=20
SILENCE_CHECKIN_NEXT_S=45
SILENCE_CHECKIN_MAX_PROMPTS=1

# Minimum words required for interruption (barge-in threshold)
MIN_INTERRUPTION_WORDS=3

# -----------------------------------------------------------------------------
# Outbound Audio Jitter Buffer (smooth TTS playback)
# -----------------------------------------------------------------------------
# Twilio PSTN audio can be jittery. The pacer will prebuffer some audio frames before
# starting a response, and can adapt within min/max if it detects underflows.
JITTER_BUFFER_MS=160
JITTER_BUFFER_MIN_MS=80
JITTER_BUFFER_MAX_MS=300
JITTER_BUFFER_ADAPT_STEP_MS=20
JITTER_BUFFER_IDLE_THRESHOLD_MS=250
